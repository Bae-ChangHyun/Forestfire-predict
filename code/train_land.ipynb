{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from osgeo import gdal, ogr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pyproj import Proj, Transformer\n",
    "import rasterio\n",
    "import natsort\n",
    "from glob import glob\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "인구밀도 분류\n",
    "[0,1,2,3,4,5,10,20,30,40,50,60,70,80,90,100,200,300,400 ,500,1000, 2000,3000, 4000,5000,6000,7000, 8000,9000,10000,11000,12000,13000,14000,15000, 16000, 20000]  \n",
    "\n",
    "토지이용도 분류\n",
    "'10': ['제1종일반주거지역', '제2종일반주거지역', '제3종일반주거지역','준주거지역', '제1종전용주거지역','제2종전용주거지역'],  # Residential 빨강\n",
    "'2': ['일반상업지역', '근린상업지역', '중심상업지역'],                             # Commercial       파랑\n",
    "'12': ['자연녹지지역', '보전녹지지역', '자연환경보전지역','보전관리지역'],          # Green Area      초록 \n",
    "'8' : ['농림지역'],                                                             # Agriculuture       연두\n",
    "'6': ['일반공업지역', '준공업지역', '전용공업지역','생산관리지역','생산녹지지역'],  # Industrial       노랑     \n",
    "'4': ['기타', '용도미지정','계획관리지역', '관리지역']                            # Miscellaneous       하늘\n",
    "\n",
    "NDVI 분류\n",
    "3월~5월 -> 4월\n",
    "6월~9월 -> 8월\n",
    "10월~11월 -> 11월\n",
    "그외 -> 1월\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data crop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_using_coordinates(InputImage, OutputImage, RefImage, latitude, longitude, CropSize):\\\n",
    "    \n",
    "    #참조 이미지의 boundary를 가져옴 \n",
    "    Image = gdal.Open(RefImage, gdal.GA_ReadOnly)\n",
    "    width = Image.RasterXSize\n",
    "    height = Image.RasterYSize\n",
    "    Image = None\n",
    "\n",
    "    \"\"\"extract vertex coordinates\"\"\"\n",
    "    rds = rasterio.open(RefImage)\n",
    "    rds.bounds\n",
    "    left = rds.bounds[0]\n",
    "    right = rds.bounds[2]\n",
    "    top = rds.bounds[3]\n",
    "    bottom = rds.bounds[1]\n",
    "\n",
    "    resolution_x = (right - left) / width\n",
    "    resolution_y = (top - bottom) / height\n",
    "\n",
    "    InputCrs = 'EPSG:4326'\n",
    "    OutputCrs ='EPSG:4326'\n",
    "    transformer = Transformer.from_crs(InputCrs, OutputCrs)\n",
    "    longitude, latitude = transformer.transform(longitude, latitude)\n",
    "    \n",
    "    left_box = latitude - (resolution_x * CropSize)\n",
    "    top_box = longitude + (resolution_y * CropSize)\n",
    "    right_box = latitude + (resolution_x * CropSize)\n",
    "    bottom_box = longitude - (resolution_y * CropSize)\n",
    "    window = (left_box, top_box, right_box, bottom_box)\n",
    "\n",
    "    gdal.Translate(OutputImage, InputImage, projWin = window)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndvi 년월별 crop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_filtering(o_data,crop_size,filepath):\n",
    "    RefImage = '../data/gw_boundary/boundary_blank_resized.tif'\n",
    "    for i in tqdm(range(len(o_data))):\n",
    "        \n",
    "        filename=str(o_data['date'][i])[:-2]\n",
    "        \n",
    "        year = filename[:4]\n",
    "        month = int(filename[4:])\n",
    "    \n",
    "        if 3 <= month <= 5: month = 4 \n",
    "        elif 6 <= month <= 9:month = 8\n",
    "        elif 10 <= month <= 11: month = 11\n",
    "        else: month = 1\n",
    "        \n",
    "        filename=year+str(month).zfill(2)\n",
    "        \n",
    "        InputImage = f'../data/geo_data/raw/NDVI/{filename}.tif' \n",
    "        OutputImage = filepath+'/Crop_NDVI_'+str(i)+'.tif'\n",
    "        \n",
    "        lon=o_data['lon'][i]\n",
    "        lat=o_data['lat'][i]\n",
    "        \n",
    "        crop_image_using_coordinates(InputImage, OutputImage, RefImage, lon, lat, crop_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 지형 crop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_train(data_n,o_data,crop_size):\n",
    "    filepath=f\"D:/firedata/crop/train/{data_n}\"\n",
    "    os.makedirs(filepath, exist_ok=True)\n",
    "    \n",
    "    print('#'*20)\n",
    "    print(f\"Start get {data_n} information\")\n",
    "    tmp=natsort.natsorted(glob(filepath+\"/*.tif\"))\n",
    "    \n",
    "    if(len(tmp)==len(o_data)):\n",
    "        print(f\"--{data_n} data already existed\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"-- Not enough file please check\")\n",
    "    \"\"\"\n",
    "    ndvi의 경우 년,월별로 데이터가 다르기 때문에\n",
    "    따로 작업을 수행하여야 한다.\n",
    "    \"\"\"\n",
    "    if(data_n==\"NDVI\"):\n",
    "        ndvi_filtering(o_data,1,filepath)\n",
    "        print(f\"{data_n} Train data crop complete\")\n",
    "        return \n",
    "    \n",
    "    InputImage = f'../data/geo_data/raw/{data_n}_gw.tif'   \n",
    "    RefImage = '../data/gw_boundary/boundary_blank_resized.tif'\n",
    "    \n",
    "    for i in tqdm(range(len(o_data))):\n",
    "        OutputImage = filepath+'/Crop_'+data_n+'_'+str(i)+'.tif'\n",
    "        \n",
    "        lon=o_data['lon'][i]\n",
    "        lat=o_data['lat'][i]\n",
    "        \n",
    "        crop_image_using_coordinates(InputImage, OutputImage, RefImage, lon, lat, crop_size)\n",
    "    print(f\"{data_n} Train data crop complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tif->npy 변환 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_npy(data_n,types,crop_size):\n",
    "    filepath=f\"D:/firedata/npy/{types}/\"\n",
    "    os.makedirs(filepath, exist_ok=True)\n",
    "    \n",
    "    if os.path.isfile(filepath+f'{data_n}_{types}.npy'):\n",
    "        print(\"Already existed\")\n",
    "        return\n",
    "    \n",
    "    files=natsort.natsorted(glob(f\"D:/firedata/crop/{types}/{data_n}/*.tif\"))\n",
    "\n",
    "    tif_list=[]\n",
    "    for i in range(len(files)):\n",
    "        tmp = cv2.imread(files[i], cv2.IMREAD_COLOR)\n",
    "        tmp = cv2.cvtColor(tmp, cv2.COLOR_BGR2RGB)\n",
    "        tmp = cv2.resize(tmp, (crop_size, crop_size))\n",
    "        tmp = tmp / 255.0\n",
    "        tif_list.append(tmp)\n",
    "\n",
    "    data=np.array(tif_list)\n",
    "    np.save(filepath+f'{data_n}_{types}.npy',data)\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Start get Height information\n",
      "--Height data already existed\n",
      "####################\n",
      "Start get Slope information\n",
      "--Slope data already existed\n",
      "####################\n",
      "Start get Landuse information\n",
      "--Landuse data already existed\n",
      "####################\n",
      "Start get population_density information\n",
      "--population_density data already existed\n",
      "####################\n",
      "Start get NDVI information\n",
      "--NDVI data already existed\n",
      "Already existed\n",
      "Already existed\n",
      "Already existed\n",
      "Already existed\n",
      "Already existed\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"../data/train_data/climate_train.csv\")\n",
    "\n",
    "crop_train('Height',train_data,1)\n",
    "crop_train('Slope',train_data,1)\n",
    "crop_train('Landuse',train_data,1)\n",
    "crop_train('population_density',train_data,1)\n",
    "crop_train('NDVI',train_data,1)\n",
    "\n",
    "convert_npy(\"Height\",'train',32)\n",
    "convert_npy(\"Slope\",'train',32)\n",
    "convert_npy(\"Landuse\",'train',32)\n",
    "convert_npy(\"population_density\",'train',32)\n",
    "convert_npy(\"NDVI\",'train',32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test land data crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강원도 경계\n",
    "N = 38.61370931\n",
    "E = 129.359995\n",
    "S = 37.03353708\n",
    "W = 127.0950376\n",
    "\n",
    "width = (E-W)/399\n",
    "height= (N-S)/277\n",
    "\n",
    "width_num,height_num=[], []\n",
    "for i in range(400):\n",
    "    width_num.append(W+width*i)\n",
    "width_num=[round(i,7) for i in width_num]\n",
    "for i in range(278):\n",
    "    height_num.append(N-height*i)\n",
    "height_num=[round(i,7) for i in height_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_test(data_n,crop_size,width_num,height_num):\n",
    "    \n",
    "    filepath=f\"D:/firedata/crop/test/{data_n}\"\n",
    "    os.makedirs(filepath, exist_ok=True)\n",
    "    \n",
    "    print('#'*20)\n",
    "    print(f\"Start get {data_n} information\")\n",
    "    tmp=natsort.natsorted(glob(filepath+\"/*.tif\"))\n",
    "    \n",
    "    if(len(tmp)==111200):\n",
    "        print(f\"--{data_n} data already existed\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"-- Not enough file please check\")\n",
    "    \n",
    "    if(data_n=='NDVI'):InputImage = f'../data/geo_data/raw/NDVI/202204.tif'   \n",
    "    else:InputImage = f'../data/geo_data/raw/{data_n}_gw.tif'   \n",
    "    \n",
    "    RefImage = '../data/gw_boundary/boundary_blank_resized.tif'\n",
    "\n",
    "    num=0\n",
    "\n",
    "    for lat in tqdm(height_num):\n",
    "        for lon in tqdm(width_num):\n",
    "            OutputImage = filepath+'/Crop_'+data_n+'_'+str(num)+'.tif'\n",
    "            num=num+1\n",
    "            crop_image_using_coordinates(InputImage, OutputImage, RefImage, lon, lat, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Start get NDVI information\n",
      "--NDVI data already existed\n",
      "####################\n",
      "Start get Height information\n",
      "--Height data already existed\n",
      "####################\n",
      "Start get Slope information\n",
      "-- Not enough file please check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 343/400 [00:18<00:03, 18.96it/s]\n",
      "  0%|          | 0/278 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m crop_test(\u001b[39m'\u001b[39m\u001b[39mNDVI\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m1\u001b[39m,width_num,height_num)\n\u001b[0;32m      2\u001b[0m crop_test(\u001b[39m'\u001b[39m\u001b[39mHeight\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m1\u001b[39m,width_num,height_num)\n\u001b[1;32m----> 3\u001b[0m crop_test(\u001b[39m'\u001b[39;49m\u001b[39mSlope\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m1\u001b[39;49m,width_num,height_num)\n\u001b[0;32m      4\u001b[0m crop_test(\u001b[39m'\u001b[39m\u001b[39mLanduse\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m1\u001b[39m,width_num,height_num)\n\u001b[0;32m      5\u001b[0m crop_test(\u001b[39m'\u001b[39m\u001b[39mpopulation_density\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m1\u001b[39m,width_num,height_num)\n",
      "Cell \u001b[1;32mIn[105], line 27\u001b[0m, in \u001b[0;36mcrop_test\u001b[1;34m(data_n, crop_size, width_num, height_num)\u001b[0m\n\u001b[0;32m     25\u001b[0m OutputImage \u001b[39m=\u001b[39m filepath\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Crop_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mdata_n\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(num)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.tif\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     26\u001b[0m num\u001b[39m=\u001b[39mnum\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> 27\u001b[0m crop_image_using_coordinates(InputImage, OutputImage, RefImage, lon, lat, crop_size)\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mcrop_image_using_coordinates\u001b[1;34m(InputImage, OutputImage, RefImage, latitude, longitude, CropSize)\u001b[0m\n\u001b[0;32m      7\u001b[0m Image \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"extract vertex coordinates\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m rds \u001b[39m=\u001b[39m rasterio\u001b[39m.\u001b[39;49mopen(RefImage)\n\u001b[0;32m     11\u001b[0m rds\u001b[39m.\u001b[39mbounds\n\u001b[0;32m     12\u001b[0m left \u001b[39m=\u001b[39m rds\u001b[39m.\u001b[39mbounds[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\forest_fire\\lib\\site-packages\\rasterio\\env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[0;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\forest_fire\\lib\\site-packages\\rasterio\\__init__.py:333\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 333\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    334\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    335\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[0;32m    336\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    337\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\_base.pyx:314\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\forest_fire\\lib\\site-packages\\rasterio\\_path.py:121\u001b[0m, in \u001b[0;36m_UnparsedPath.name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Encapsulates legacy GDAL filenames\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[39mAttributes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m    The legacy GDAL filename.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m path \u001b[39m=\u001b[39m attr\u001b[39m.\u001b[39mib()\n\u001b[1;32m--> 121\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    123\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The unparsed path's original path\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crop_test('NDVI',1,width_num,height_num)\n",
    "crop_test('Height',1,width_num,height_num)\n",
    "crop_test('Slope',1,width_num,height_num)\n",
    "crop_test('Landuse',1,width_num,height_num)\n",
    "crop_test('population_density',1,width_num,height_num)\n",
    "\n",
    "\n",
    "convert_npy(\"Height\",'train',32)\n",
    "convert_npy(\"Slope\",'train',32)\n",
    "convert_npy(\"Landuse\",'train',32)\n",
    "convert_npy(\"population_density\",'train',32)\n",
    "convert_npy(\"NDVI\",'train',32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_npy(\"Height\",'test',24)\n",
    "# convert_npy(\"Slope\",'test',24)\n",
    "# convert_npy(\"Landuse\",'test',24)\n",
    "# convert_npy(\"population_density\",'test',24)\n",
    "# convert_npy(\"Height\",'train',24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forest_fire",
   "language": "python",
   "name": "forest_fire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
